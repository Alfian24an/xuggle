/* ----------------------------------------------------------------------------
 * This file was automatically generated by SWIG (http://www.swig.org).
 * Version 1.3.37
 *
 * Do not make changes to this file unless you know what you are doing--modify
 * the SWIG interface file instead.
 * ----------------------------------------------------------------------------- */

package com.xuggle.xuggler;
import com.xuggle.ferry.*;
/**
 * Information about how video data is formatted in an {@link IVideoPicture} 
 * object.  
 * This specifies the color space and how many bits pixel data takes. 
 * It also  
 * includes some utility methods for dealing with {@link Type#YUV420P} 
 * data; the  
 * most common type of encoding used in video files I've run across. 
 *  
 */
public class IPixelFormat extends RefCounted {
  // JNIHelper.swg: Start generated code
  // >>>>>>>>>>>>>>>>>>>>>>>>>>>
  /**
   * This method is only here to use some references and remove
   * a Eclipse compiler warning.
   */
  @SuppressWarnings("unused")
  private void noop()
  {
    IBuffer.make(null, 1);
  }
   
  private volatile long swigCPtr;

  /**
   * Internal Only.
   */
  protected IPixelFormat(long cPtr, boolean cMemoryOwn) {
    super(XugglerJNI.SWIGIPixelFormatUpcast(cPtr), cMemoryOwn);
    swigCPtr = cPtr;
  }
  
  /**
   * Internal Only.
   */
  protected IPixelFormat(long cPtr, boolean cMemoryOwn,
      java.util.concurrent.atomic.AtomicLong ref)
  {
    super(XugglerJNI.SWIGIPixelFormatUpcast(cPtr),
     cMemoryOwn, ref);
    swigCPtr = cPtr;
  }
    
  /**
   * Internal Only.  Not part of public API.
   *
   * Get the raw value of the native object that obj is proxying for.
   *   
   * @param obj The java proxy object for a native object.
   * @return The raw pointer obj is proxying for.
   */
  public static long getCPtr(IPixelFormat obj) {
    if (obj == null) return 0;
    return obj.getMyCPtr();
  }

  /**
   * Internal Only.  Not part of public API.
   *
   * Get the raw value of the native object that we're proxying for.
   *   
   * @return The raw pointer we're proxying for.
   */  
  public long getMyCPtr() {
    if (swigCPtr == 0) throw new IllegalStateException("underlying native object already deleted");
    return swigCPtr;
  }
  
  /**
   * Create a new IPixelFormat object that is actually referring to the
   * exact same underlying native object.
   *
   * @return the new Java object.
   */
  @Override
  public IPixelFormat copyReference() {
    if (swigCPtr == 0)
      return null;
    else
      return new IPixelFormat(swigCPtr, swigCMemOwn, getJavaRefCount());
  }

  /**
   * Compares two values, returning true if the underlying objects in native code are the same object.
   *
   * That means you can have two different Java objects, but when you do a comparison, you'll find out
   * they are the EXACT same object.
   *
   * @return True if the underlying native object is the same.  False otherwise.
   */
  public boolean equals(Object obj) {
    boolean equal = false;
    if (obj instanceof IPixelFormat)
      equal = (((IPixelFormat)obj).swigCPtr == this.swigCPtr);
    return equal;
  }
  
  /**
   * Get a hashable value for this object.
   *
   * @return the hashable value.
   */
  public int hashCode() {
     return (int)swigCPtr;
  }
  
  // <<<<<<<<<<<<<<<<<<<<<<<<<<<
  // JNIHelper.swg: End generated code
  
/**
 * Returns the byte for the coordinates at x and y for the color component 
 * c.  
 * @param	frame The frame to get the byte from  
 * @param	x X coordinate in pixels, where 0 is the left hand edge of 
 *		 the image.  
 * @param	y Y coordinate in pixels, where 0 is the top edge of the image. 
 *		  
 * @param	c YUVColor component  
 * std::exception frame is null, the coordinates are invalid, or if 
 * the pixel format is not YUV420P  
 * @return	the pixel byte for that x, y, c combination  
 */
  public static short getYUV420PPixel(IVideoPicture frame, int x, int y, IPixelFormat.YUVColorComponent c) {
    return XugglerJNI.IPixelFormat_getYUV420PPixel(IVideoPicture.getCPtr(frame), frame, x, y, c.swigValue());
  }

/**
 * Sets the value of the color component c at the coordinates x and 
 * y in the given frame.  
 * @param	frame The frame to set the byte in  
 * @param	x X coordinate in pixels, where 0 is the left hand edge of 
 *		 the image.  
 * @param	y Y coordinate in pixels, where 0 is the top edge of the image. 
 *		  
 * @param	c YUVColor component to set  
 * @param	value The new value of that pixel color component  
 * std::exception frame is null, the coordinates are invalid, or if 
 * the pixel format is not YUV420P  
 */
  public static void setYUV420PPixel(IVideoPicture frame, int x, int y, IPixelFormat.YUVColorComponent c, short value) {
    XugglerJNI.IPixelFormat_setYUV420PPixel(IVideoPicture.getCPtr(frame), frame, x, y, c.swigValue(), value);
  }

/**
 * For a given x and y in a frame, and a given color components, this 
 * method  
 * tells you how far into the actual data you'd have to go to find the 
 * byte that  
 * represents that color/coordinate combination.  
 * @param	frame The frame to get the byte from  
 * @param	x X coordinate in pixels, where 0 is the left hand edge of 
 *		 the image.  
 * @param	y Y coordinate in pixels, where 0 is the top edge of the image. 
 *		  
 * @param	c YUVColor component  
 * std::exception frame is null, the coordinates are invalid, or if 
 * the pixel format is not YUV420P  
 * @return	the offset in bytes, starting from the start of the frame 
 *		 data, where  
 * the data for this pixel resides.  
 */
  public static int getYUV420PPixelOffset(IVideoPicture frame, int x, int y, IPixelFormat.YUVColorComponent c) {
    return XugglerJNI.IPixelFormat_getYUV420PPixelOffset(IVideoPicture.getCPtr(frame), frame, x, y, c.swigValue());
  }

  public enum Type {
  /**
   * Pixel format. Notes:
   * RGB32 is handled in an endian-specific manner. A RGBA
   * color is put together as:
   * (A << 24) | (R << 16) | (G << 8) | B
   * This is stored as BGRA on little endian CPU architectures and ARGB 
   * on
   * big endian CPUs.
   * When the pixel format is palettized RGB (PAL8), the palettized
   * image data is stored in AVFrame.data[0]. The palette is transported 
   * in
   * AVFrame.data[1] and, is 1024 bytes long (256 4-byte entries) and 
   * is
   * formatted the same as in RGB32 described above (i.e., it is
   * also endian-specific). Note also that the individual RGB palette 
   *
   * components stored in AVFrame.data[1] should be in the range 0..255. 
   *
   * This is important as many custom PAL8 video codecs that were designed 
   *
   * to run on the IBM VGA graphics adapter use 6-bit palette components. 
   *
   */
    NONE(XugglerJNI.IPixelFormat_NONE_get()),
    YUV420P,
    YUYV422,
    RGB24,
    BGR24,
    YUV422P,
    YUV444P,
    YUV410P,
    YUV411P,
    GRAY8,
    MONOWHITE,
    MONOBLACK,
    PAL8,
    YUVJ420P,
    YUVJ422P,
    YUVJ444P,
    XVMC_MPEG2_MC,
    XVMC_MPEG2_IDCT,
    UYVY422,
    UYYVYY411,
    BGR8,
    BGR4,
    BGR4_BYTE,
    RGB8,
    RGB4,
    RGB4_BYTE,
    NV12,
    NV21,
    ARGB,
    RGBA,
    ABGR,
    BGRA,
    GRAY16BE,
    GRAY16LE,
    YUV440P,
    YUVJ440P,
    YUVA420P,
    VDPAU_H264,
    VDPAU_MPEG1,
    VDPAU_MPEG2,
    VDPAU_WMV3,
    VDPAU_VC1,
    RGB48BE,
    RGB48LE,
    RGB565BE,
    RGB565LE,
    RGB555BE,
    RGB555LE,
    BGR565BE,
    BGR565LE,
    BGR555BE,
    BGR555LE,
    VAAPI_MOCO,
    VAAPI_IDCT,
    VAAPI_VLD,
    YUV420PLE,
    YUV420PBE,
    YUV422PLE,
    YUV422PBE,
    YUV444PLE,
    YUV444PBE,
    NB;

    public final int swigValue() {
      return swigValue;
    }

    public static Type swigToEnum(int swigValue) {
      Type[] swigValues = Type.class.getEnumConstants();
      if (swigValue < swigValues.length && swigValue >= 0 && swigValues[swigValue].swigValue == swigValue)
        return swigValues[swigValue];
      for (Type swigEnum : swigValues)
        if (swigEnum.swigValue == swigValue)
          return swigEnum;
      throw new IllegalArgumentException("No enum " + Type.class + " with value " + swigValue);
    }

    @SuppressWarnings("unused")
    private Type() {
      this.swigValue = SwigNext.next++;
    }

    @SuppressWarnings("unused")
    private Type(int swigValue) {
      this.swigValue = swigValue;
      SwigNext.next = swigValue+1;
    }

    @SuppressWarnings("unused")
    private Type(Type swigEnum) {
      this.swigValue = swigEnum.swigValue;
      SwigNext.next = this.swigValue+1;
    }

    private final int swigValue;

    private static class SwigNext {
      private static int next = 0;
    }
  }

  public enum YUVColorComponent {
    YUV_Y(XugglerJNI.IPixelFormat_YUV_Y_get()),
    YUV_U(XugglerJNI.IPixelFormat_YUV_U_get()),
    YUV_V(XugglerJNI.IPixelFormat_YUV_V_get());

    public final int swigValue() {
      return swigValue;
    }

    public static YUVColorComponent swigToEnum(int swigValue) {
      YUVColorComponent[] swigValues = YUVColorComponent.class.getEnumConstants();
      if (swigValue < swigValues.length && swigValue >= 0 && swigValues[swigValue].swigValue == swigValue)
        return swigValues[swigValue];
      for (YUVColorComponent swigEnum : swigValues)
        if (swigEnum.swigValue == swigValue)
          return swigEnum;
      throw new IllegalArgumentException("No enum " + YUVColorComponent.class + " with value " + swigValue);
    }

    @SuppressWarnings("unused")
    private YUVColorComponent() {
      this.swigValue = SwigNext.next++;
    }

    @SuppressWarnings("unused")
    private YUVColorComponent(int swigValue) {
      this.swigValue = swigValue;
      SwigNext.next = swigValue+1;
    }

    @SuppressWarnings("unused")
    private YUVColorComponent(YUVColorComponent swigEnum) {
      this.swigValue = swigEnum.swigValue;
      SwigNext.next = this.swigValue+1;
    }

    private final int swigValue;

    private static class SwigNext {
      private static int next = 0;
    }
  }

}
